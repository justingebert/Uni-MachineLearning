{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.332818300Z",
     "start_time": "2023-07-04T18:40:14.280292600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data set\n",
    "\n",
    "There will be several data sets we therefore define abstract interface an implement concrete classes that derive the interface below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.512772900Z",
     "start_time": "2023-07-04T18:40:14.292264400Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(ABC):\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_train_x(self):\n",
    "        \"\"\" Retrieve the input data of the training \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_train_y(self):\n",
    "        \"\"\" Retrieve the output data of the training \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_test_x(self):\n",
    "        \"\"\" Retrieve the input data of the test \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_test_y(self):\n",
    "        \"\"\" Retrieve the output data of the test \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.548189700Z",
     "start_time": "2023-07-04T18:40:14.306968600Z"
    }
   },
   "outputs": [],
   "source": [
    "class XORDataset(Dataset):\n",
    "    \n",
    "    _x = None\n",
    "    _y = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._x = np.array([[0,0],[1, 0],[0,1],[1,1]])\n",
    "        self._y = np.array([[0],[1],[1],[0]])\n",
    "    \n",
    "    def get_train_x(self):\n",
    "        return self._x\n",
    "    \n",
    "    def get_train_y(self):\n",
    "        return self._y\n",
    "    \n",
    "    def get_test_x(self):\n",
    "        return self._x\n",
    "    \n",
    "    def get_test_y(self):\n",
    "        return self._y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "class CreditDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = np.loadtxt(\"../data/german_credit.csv\", delimiter=\",\", skiprows=1)\n",
    "        self.x = self.data[:, :-1]\n",
    "        self.y = self.data[:, -1]\n",
    "\n",
    "        # Perform one-hot encoding on the y data\n",
    "        self.y_encoded = np.zeros((len(self.y), 3))\n",
    "        for i, label in enumerate(self.y):\n",
    "            if label == 1:\n",
    "                self.y_encoded[i, 0] = 1\n",
    "            elif label == 2:\n",
    "                self.y_encoded[i, 1] = 1\n",
    "            elif label == 3:\n",
    "                self.y_encoded[i, 2] = 1\n",
    "\n",
    "        # Split the data into train and test sets\n",
    "        self.train_x = self.x[:-99]\n",
    "        self.train_y = self.y_encoded[:-99]\n",
    "        self.test_x = self.x[-99:]\n",
    "        self.test_y = self.y_encoded[-99:]\n",
    "\n",
    "    def get_train_x(self):\n",
    "        return self.train_x\n",
    "\n",
    "    def get_train_y(self):\n",
    "        return self.train_y\n",
    "\n",
    "    def get_test_x(self):\n",
    "        return self.test_x\n",
    "\n",
    "    def get_test_y(self):\n",
    "        return self.test_y\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.575708300Z",
     "start_time": "2023-07-04T18:40:14.321708400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations of a neural network\n",
    "\n",
    "Every neural network consists of serveral operations which gets executed during a forward and backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.581155600Z",
     "start_time": "2023-07-04T18:40:14.335810900Z"
    }
   },
   "outputs": [],
   "source": [
    "class Operation(ABC):\n",
    "        \n",
    "    @abstractmethod\n",
    "    def forward(self, data):\n",
    "        \"\"\" Forward pass of the operation. Process the input data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : ndarray\n",
    "            Data from the last layer\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        result : ndarray\n",
    "            The result of processing the input data\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def backward(self, gradient_data):\n",
    "        \"\"\" Backward pass of the operation. The gradient data is uses \n",
    "        to compute the changes of weights and the partial gradient of \n",
    "        the this layer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        gradient_data : ndarray\n",
    "            Gradient data from the previous layer during the backward pass\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        result : ndarray\n",
    "            The partial gradient of the this layer with respect to the incoming gradient_data\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO implement the different operations of a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.581155600Z",
     "start_time": "2023-07-04T18:40:14.346694600Z"
    }
   },
   "outputs": [],
   "source": [
    "class BiasOperation(Operation):\n",
    "    \"\"\" Bias operation in the network \"\"\"\n",
    "    \n",
    "    def forward(self, data):\n",
    "        print(\"bias data shape:\", data.shape)\n",
    "        return np.hstack((data, np.ones((data.shape[0], 1))))\n",
    "    \n",
    "    def backward(self, gradient_data):\n",
    "        return gradient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.607781100Z",
     "start_time": "2023-07-04T18:40:14.361701100Z"
    }
   },
   "outputs": [],
   "source": [
    "class SigmoidOperation(Operation):\n",
    "    \"\"\" Sigmoid function in the network \"\"\"\n",
    "    \n",
    "    def forward(self, data):\n",
    "        print(\"sigmoid data shape:\", data.shape)\n",
    "        return 1 / (1 + np.exp(-data))\n",
    "    \n",
    "    def backward(self, gradient_data):\n",
    "        return gradient_data * (1 - gradient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.609748600Z",
     "start_time": "2023-07-04T18:40:14.375372700Z"
    }
   },
   "outputs": [],
   "source": [
    "class LossOperation(Operation):\n",
    "    \"\"\" Loss function in the network \"\"\"    \n",
    "    _y = None\n",
    "    \n",
    "    def set_y(self, y):\n",
    "        \"\"\" Store the correct y value for later comparison \"\"\"\n",
    "        self._y = y\n",
    "    \n",
    "    def forward(self, data):\n",
    "        print(\"loss data shape:\", data.shape)\n",
    "        return data\n",
    "    \n",
    "    def backward(self, gradient_data):\n",
    "        return gradient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.609748600Z",
     "start_time": "2023-07-04T18:40:14.393609200Z"
    }
   },
   "outputs": [],
   "source": [
    "class InnerProductOperation(Operation):\n",
    "    \"\"\" Inner Product, Fully Connected or Dense operation in the network \"\"\"\n",
    "    _learn_rate = 0.1\n",
    "    _weights = None\n",
    "    _input_data = None\n",
    "    \n",
    "    def __init__(self, input_units, hidden_units):\n",
    "        self._weights = np.random.uniform(low = -1, high = 1, size = (input_units, hidden_units))\n",
    "    \n",
    "    def set_learn_rate(self, learn_rate):\n",
    "        \"\"\" Change the learn rate \"\"\"\n",
    "        self._learn_rate = learn_rate\n",
    "    \n",
    "    def forward(self, data):\n",
    "        print(\"data shape:\", data.shape)\n",
    "        print(\"weights shape:\", self._weights.shape)\n",
    "        self._input_data = data\n",
    "        return np.matmul(data, self._weights)\n",
    "    \n",
    "    def backward(self, gradient_data):\n",
    "        print(\"gradient_data shape:\", gradient_data.shape)\n",
    "        gradient = np.matmul(gradient_data, self._weights.T)\n",
    "        print(\"gradient shape:\", gradient.shape)\n",
    "        print(\"input_data shape:\", self._input_data.shape)\n",
    "        print(\"weights shape:\", self._weights.shape)\n",
    "        self._weights += self._learn_rate * np.matmul(gradient_data.T, self._input_data)\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the neural network \n",
    "\n",
    "Using the operations we can now build our own neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.610779900Z",
     "start_time": "2023-07-04T18:40:14.419969300Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(ABC):\n",
    "    \n",
    "    _ops = []\n",
    "    _train_errors = []\n",
    "    _test_accuracies = []\n",
    "    \n",
    "    def get_test_accuracies(self):\n",
    "        return self._test_accuracies\n",
    "    \n",
    "    def get_train_errors(self):\n",
    "        return self._train_errors\n",
    "    \n",
    "    def predict(self,data):\n",
    "        return self.forwardPass(data, len(self._ops)-1)\n",
    "    \n",
    "    def forwardPass(self,data, layers):\n",
    "        result = data\n",
    "        for op in range(0,layers):     \n",
    "            result = self._ops[op].forward(result)\n",
    "            print(\"result shape:\", result.shape)\n",
    "        return (result)\n",
    "        \n",
    "    def backwardPass(self, data, layers):\n",
    "        result = data\n",
    "        for op in range(len(self._ops)-1, len(self._ops) - layers , -1):\n",
    "            result = self._ops[op].backward(result)\n",
    "        return result\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train(self, dataset, epochs, learn_rate, error_output_every):\n",
    "        \"\"\" Train the neural network with the data set several epochs.\n",
    "        Compute the train error and test accurarcy after some iterations.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : ndarray\n",
    "            Data from the last layer\n",
    "        epochs : int\n",
    "            Number of epochs to be trained\n",
    "        learn_rate : float\n",
    "            Learn rated to be used to changing the weights of the network\n",
    "        error_output_every : int\n",
    "            After how many iterations should the train error and test accurarcy be calculated\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.610779900Z",
     "start_time": "2023-07-04T18:40:14.434950800Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogicGateNetwork(Network):\n",
    "    \n",
    "    def __init__(self, input_units, output_units, hidden_units):\n",
    "        self._ops = []\n",
    "        self._ops.append(BiasOperation())\n",
    "        print(\"input_units:\", input_units)\n",
    "        self._ops.append(InnerProductOperation(input_units +1, hidden_units))\n",
    "        self._ops.append(SigmoidOperation())\n",
    "        self._ops.append(BiasOperation())\n",
    "        self._ops.append(InnerProductOperation(hidden_units +1, output_units))\n",
    "        self._ops.append(SigmoidOperation())\n",
    "        self._ops.append(LossOperation())\n",
    "        print('Setup XOR Network')\n",
    "        \n",
    "    def train(self, dataset, epochs, learn_rate, error_output_every):\n",
    "        print('Start training of the XOR network ...')\n",
    "        \n",
    "        #clear old train errors and test accuracies\n",
    "        self._train_errors = []\n",
    "        self._test_accuracies = []\n",
    "        \n",
    "        # fix learn rate for all layers\n",
    "        for op in self._ops:\n",
    "            if type(op) == InnerProductOperation:\n",
    "                op.set_learn_rate(learn_rate)\n",
    "                \n",
    "        # get the last layer (loss layer)\n",
    "        last_layer = self._ops[len(self._ops)-1]\n",
    "       \n",
    "        # get the train and test data\n",
    "        train_x = dataset.get_train_x()\n",
    "        train_y = dataset.get_train_y()\n",
    "        test_x = dataset.get_test_x()\n",
    "        test_y = dataset.get_test_y()\n",
    "        \n",
    "        # train the network\n",
    "        for e in range(0, epochs+1):\n",
    "            \n",
    "            # forward propagation\n",
    "            print(\"train_x shape:\", train_x.shape)\n",
    "            hypothese = self.predict(train_x)\n",
    "            \n",
    "            # place the target data in the loss layer\n",
    "            last_layer.set_y(train_y)\n",
    "            \n",
    "            # backward propagate and change the weights\n",
    "            self.backwardPass(hypothese, len(self._ops))\n",
    "            \n",
    "            # print the train and test error rate after 100 epochs\n",
    "            if (e % error_output_every == 0):\n",
    "                \n",
    "                # compute train error with the train data\n",
    "                error = last_layer.forward(hypothese).sum()/train_x.shape[0]\n",
    "                self._train_errors.append(error)\n",
    "                \n",
    "                # compute test accuracy with the test data\n",
    "                accuracy = (np.where(self.predict(test_x) > 0.5,1,0) == test_y).all(axis=1).sum() / test_x.shape[0] * 100\n",
    "                self._test_accuracies.append(accuracy)\n",
    "                print('Epoche ',e, 'with error:', error, 'and accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the LogicGateNetwork and XORDataset to train the network for solving the XOR problem\n",
    "Change the number of hidden neurons in the network and learn rate to converge faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T18:40:14.634281800Z",
     "start_time": "2023-07-04T18:40:14.448147200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_units: 2\n",
      "Setup XOR Network\n",
      "Start training of the XOR network ...\n",
      "train_x shape: (4, 2)\n",
      "bias data shape: (4, 2)\n",
      "result shape: (4, 3)\n",
      "data shape: (4, 3)\n",
      "weights shape: (3, 5)\n",
      "result shape: (4, 5)\n",
      "sigmoid data shape: (4, 5)\n",
      "result shape: (4, 5)\n",
      "bias data shape: (4, 5)\n",
      "result shape: (4, 6)\n",
      "data shape: (4, 6)\n",
      "weights shape: (6, 2)\n",
      "result shape: (4, 2)\n",
      "sigmoid data shape: (4, 2)\n",
      "result shape: (4, 2)\n",
      "gradient_data shape: (4, 2)\n",
      "gradient shape: (4, 6)\n",
      "input_data shape: (4, 6)\n",
      "weights shape: (6, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,2) (2,6) (6,2) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[163], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m dataSet \u001B[38;5;241m=\u001B[39m XORDataset()\n\u001B[0;32m      8\u001B[0m network \u001B[38;5;241m=\u001B[39m LogicGateNetwork(dataSet\u001B[38;5;241m.\u001B[39mget_train_x()\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], dataSet\u001B[38;5;241m.\u001B[39mget_train_x()\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], hidden_units)\n\u001B[1;32m---> 10\u001B[0m network\u001B[38;5;241m.\u001B[39mtrain(dataSet, training_iterations, learn_rate, error_output_every)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfinal prediction: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m, network\u001B[38;5;241m.\u001B[39mpredict(dataSet\u001B[38;5;241m.\u001B[39mget_test_x()))\n\u001B[0;32m     12\u001B[0m accuracies \u001B[38;5;241m=\u001B[39m network\u001B[38;5;241m.\u001B[39mget_test_accuracies()\n",
      "Cell \u001B[1;32mIn[162], line 47\u001B[0m, in \u001B[0;36mLogicGateNetwork.train\u001B[1;34m(self, dataset, epochs, learn_rate, error_output_every)\u001B[0m\n\u001B[0;32m     44\u001B[0m last_layer\u001B[38;5;241m.\u001B[39mset_y(train_y)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# backward propagate and change the weights\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackwardPass(hypothese, \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ops))\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# print the train and test error rate after 100 epochs\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (e \u001B[38;5;241m%\u001B[39m error_output_every \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m     51\u001B[0m     \n\u001B[0;32m     52\u001B[0m     \u001B[38;5;66;03m# compute train error with the train data\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[161], line 26\u001B[0m, in \u001B[0;36mNetwork.backwardPass\u001B[1;34m(self, data, layers)\u001B[0m\n\u001B[0;32m     24\u001B[0m result \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m op \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ops)\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ops) \u001B[38;5;241m-\u001B[39m layers , \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m---> 26\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ops[op]\u001B[38;5;241m.\u001B[39mbackward(result)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "Cell \u001B[1;32mIn[160], line 26\u001B[0m, in \u001B[0;36mInnerProductOperation.backward\u001B[1;34m(self, gradient_data)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_data shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_data\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweights shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_weights\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_weights \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_learn_rate \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mmatmul(gradient_data\u001B[38;5;241m.\u001B[39mT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_data)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m gradient\n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (6,2) (2,6) (6,2) "
     ]
    }
   ],
   "source": [
    "training_iterations = 5000\n",
    "error_output_every = 1000\n",
    "learn_rate = 0.7\n",
    "hidden_units = 5\n",
    "np.random.seed(5)\n",
    "\n",
    "dataSet = XORDataset()\n",
    "network = LogicGateNetwork(dataSet.get_train_x().shape[1], dataSet.get_train_x().shape[1], hidden_units)\n",
    "\n",
    "network.train(dataSet, training_iterations, learn_rate, error_output_every)\n",
    "print('final prediction: \\n', network.predict(dataSet.get_test_x()))\n",
    "accuracies = network.get_test_accuracies()\n",
    "print('overall accuracy = ', accuracies[len(network.get_test_accuracies())-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T18:40:14.531670100Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, training_iterations, len(accuracies)), accuracies, 'b', label ='xor data')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.axis([0, training_iterations, 0, 100 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CreditNetwork(Network):\n",
    "    def __init__(self, input_units, output_units, hidden_units):\n",
    "        self._ops = []\n",
    "        self._ops.append(BiasOperation())\n",
    "        self._ops.append(InnerProductOperation(input_units + 1, hidden_units))\n",
    "        self._ops.append(SigmoidOperation())\n",
    "        self._ops.append(BiasOperation())\n",
    "        self._ops.append(InnerProductOperation(hidden_units + 1, output_units))\n",
    "        self._ops.append(SigmoidOperation())\n",
    "        self._ops.append(LossOperation())\n",
    "        print('Setup Credit Network')\n",
    "\n",
    "    def train(self, dataset, epochs, learn_rate, error_output_every):\n",
    "        print('Start training of the Credit network ...')\n",
    "\n",
    "        # Clear old train errors and test accuracies\n",
    "        self._train_errors = []\n",
    "        self._test_accuracies = []\n",
    "\n",
    "        # Fix learn rate for all layers\n",
    "        for op in self._ops:\n",
    "            if type(op) == InnerProductOperation:\n",
    "                op.set_learn_rate(learn_rate)\n",
    "\n",
    "        # Get the last layer (loss layer)\n",
    "        last_layer = self._ops[len(self._ops) - 1]\n",
    "\n",
    "        # Get the train and test data\n",
    "        train_x = dataset.get_train_x()\n",
    "        train_y = dataset.get_train_y()\n",
    "        test_x = dataset.get_test_x()\n",
    "        test_y = dataset.get_test_y()\n",
    "\n",
    "        # Train the network\n",
    "        for e in range(0, epochs + 1):\n",
    "            # Forward propagation\n",
    "            hypothese = self.predict(train_x)\n",
    "\n",
    "            # Place the target data in the loss layer\n",
    "            last_layer.set_y(train_y)\n",
    "\n",
    "            # Backward propagate and change the weights\n",
    "            self.backwardPass(hypothese, len(self._ops))\n",
    "\n",
    "            # Print the train error and test accuracy after a certain number of epochs\n",
    "            if e % error_output_every == 0:\n",
    "                # Compute train error with the train data\n",
    "                error = last_layer.forward(hypothese).sum() / train_x.shape[0]\n",
    "                self._train_errors.append(error)\n",
    "\n",
    "                # Compute test accuracy with the test data\n",
    "                predictions = self.predict(test_x)\n",
    "                accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(test_y, axis=1))\n",
    "                self._test_accuracies.append(accuracy * 100)\n",
    "                print('Epoch', e, 'with error:', error, 'and accuracy:', accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T18:40:14.533671400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_iterations = 5000\n",
    "error_output_every = 1000\n",
    "learn_rate = 0.7\n",
    "hidden_units = 5\n",
    "np.random.seed(5)\n",
    "\n",
    "dataSet = CreditDataset()\n",
    "network = LogicGateNetwork(dataSet.get_train_x().shape[1], dataSet.get_train_x().shape[1], hidden_units)\n",
    "\n",
    "network.train(dataSet, training_iterations, learn_rate, error_output_every)\n",
    "print('final prediction: \\n', network.predict(dataSet.get_test_x()))\n",
    "accuracies = network.get_test_accuracies()\n",
    "print('overall accuracy = ', accuracies[len(network.get_test_accuracies())-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T18:40:14.538189700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T18:40:14.540189500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
